Large language models (LLMs) have demonstrated remarkable capabilities across diverse tasks, yet their deployment faces three critical challenges: unreliable outputs that may contain errors or hallucinations, limited control over generation behavior, and inefficient training procedures that waste computational resources on redundant data. This thesis addresses these challenges through a unified approach that leverages signals from the model's forward pass---both internal representations and output distributions---to improve reliability, control, and training efficiency.

We present three interconnected studies. First, we investigate uncertainty estimation by analyzing the relationship between token-level entropy patterns and answer correctness. Our experiments on MMLU-Pro demonstrate that entropy-based features, particularly the ratio of maximum to minimum token entropy, achieve ROC-AUC scores up to 0.83 for predicting incorrect answers, outperforming baseline confidence measures. Second, we explore the geometric structure of multilingual representations in LLM latent space, discovering that language-specific directions can be identified through PCA with 95--99\% classification accuracy. By steering activations along these directions, we reduce unwanted code-switching by up to 55\% as measured by KL divergence, without requiring additional training. Third, we develop a complexity-aware fine-tuning pipeline that uses entropy to stratify training data and applies targeted interventions: direct supervised fine-tuning for simple examples and chain-of-thought distillation for complex ones. This approach achieves accuracy improvements from 0.39 to 0.52 (Qwen-2.5-1.5B) and 0.51 to 0.64 (Qwen-2.5-3B) while using 81\% less training data than baseline methods.

Together, these contributions demonstrate that accessible signals from a single forward pass provide valuable information for addressing fundamental challenges in LLM deployment. The methods developed require no architectural modifications or expensive retraining, making them practical for real-world applications.
