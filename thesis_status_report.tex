\documentclass[12pt,a4paper]{article}

% ============================================
% PACKAGES
% ============================================
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{times}
\usepackage[margin=2.5cm]{geometry}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{amsmath,amssymb}
\usepackage{hyperref}
\usepackage{natbib}
\usepackage{enumitem}
\usepackage{xcolor}
\usepackage{tocloft}
\usepackage{titlesec}
\usepackage{fancyhdr}
\usepackage{setspace}

% ============================================
% FORMATTING
% ============================================
\hypersetup{
  colorlinks=true,
  linkcolor=blue,
  citecolor=blue,
  urlcolor=blue
}

\pagestyle{fancy}
\fancyhf{}
\fancyhead[R]{\thepage}
\renewcommand{\headrulewidth}{0pt}

\titleformat{\section}{\normalfont\Large\bfseries}{\thesection}{1em}{}
\titleformat{\subsection}{\normalfont\large\bfseries}{\thesubsection}{1em}{}

\setlength{\parindent}{0pt}
\setlength{\parskip}{10pt}

% ============================================
% TITLE PAGE
% ============================================
\begin{document}

\begin{titlepage}
  \centering
  \vspace*{1cm}

  {\LARGE\textbf{Skoltech}}\\[0.5cm]
  \rule{\textwidth}{1pt}\\[2cm]

  {\Large\textbf{MASTER'S THESIS STATUS REPORT}}\\[0.5cm]

  {\Large\textbf{From Internal Representations to Output Distributions:\\
  Lightweight Signals for LLM Control and Efficiency}}\\[3cm]

  {\large Master's Educational Program: \textbf{Data Science}}\\[1cm]

  {\large Student: \textbf{Andrey Goncharov}}\\[0.5cm]
  {\large Supervisor: \textbf{Alexey Zaytsev}}\\[3cm]

  {\large Moscow 2025}\\[2cm]

  \rule{\textwidth}{0.5pt}\\[0.5cm]
  {\small Copyright 2025 Author. All rights reserved.\\
  The author hereby grants to Skoltech permission to reproduce and to distribute publicly paper and electronic copies of this thesis document in whole and in part in any medium now known or hereafter created.}

\end{titlepage}

% ============================================
% TABLE OF CONTENTS
% ============================================
\tableofcontents
\newpage

% ============================================
% SECTION 1: RESEARCH PROBLEM
% ============================================
\section{Research Problem / Questions}

Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse tasks, yet their deployment in production systems faces critical challenges related to \textbf{controllability} and \textbf{training efficiency}. This thesis investigates how signals extracted from LLMs---both from \textbf{internal representations} (hidden state geometry) and their \textbf{external reflection in output distributions} (token-level entropy)---can be leveraged for efficiency gains at two stages:

\begin{itemize}[leftmargin=*]
  \item \textbf{Training time:} Output entropy guides data stratification for more efficient fine-tuning (Study 3).
  \item \textbf{Runtime:} Output entropy enables uncertainty characterization without additional inference (Study 1), while latent space structure enables generation control without retraining (Study 2)---with potential for future efficient runtime interventions.
\end{itemize}

The key insight is that the forward pass of an LLM produces a rich hierarchy of information: hidden states encode high-level structure (e.g., language identity), while output logit distributions reflect the model's confidence and uncertainty. This thesis addresses three interconnected problems:

\subsection{Uncertainty Characterization}
LLMs often generate responses with unjustified confidence, particularly in knowledge-intensive domains. The confidence gap between a model's certainty and actual correctness poses risks in high-stakes applications like healthcare, law, and education, where overconfidence in incorrect answers can lead to harmful decisions.

\textbf{Research Question 1:} \textit{How can we characterize LLM uncertainty using token-level entropy, and under what conditions are these uncertainty signals informative?}

\subsection{Latent Space Structure}
LLMs encode high-level concepts in their hidden states, but the geometry of these representations remains underexplored. Understanding how ideas---such as language identity, topic, or style---are represented in latent space opens the door to direct manipulation of model behavior without retraining. This thesis presents early exploration of latent space structure, using language identity as an ideal test case: it is discrete, easily verifiable, and has immediate practical applications (e.g., mitigating unintended code-switching). Success here suggests potential for future efficient runtime interventions on other concepts.

\textbf{Research Question 2:} \textit{Can we identify interpretable structure in LLM latent space, and can manipulating this structure control generation behavior?}

\subsection{Training Inefficiency}
Current fine-tuning approaches apply uniform strategies across all data, ignoring that different question complexities require different learning approaches. This one-size-fits-all methodology leads to suboptimal performance and inefficient use of computational resources.

\textbf{Research Question 3:} \textit{Can uncertainty signals guide complexity-aware training strategies to improve fine-tuning efficiency while reducing data requirements?}

\subsection{Unifying Theme}
The central thesis is that the LLM forward pass provides two complementary sources of actionable signal:
\begin{itemize}[leftmargin=*]
  \item \textbf{Output distributions:} Token-level entropy reflects model confidence and task complexity, enabling runtime uncertainty characterization (Study 1) and training-time data stratification for efficient fine-tuning (Study 3).
  \item \textbf{Internal representations:} Hidden states encode interpretable structure (e.g., language identity) that can be directly manipulated for runtime generation control. This thesis presents early exploration of latent space geometry (Study 2), demonstrating feasibility and opening directions for future efficient runtime interventions.
\end{itemize}
Together, these signals enable efficiency gains at both training time (smarter fine-tuning) and runtime (uncertainty-aware systems, generation control).

% ============================================
% SECTION 2: GOALS AND OBJECTIVES
% ============================================
\section{Goals and Objectives}

\subsection{Primary Goal}
To demonstrate that signals from LLM internals---both hidden state geometry and output entropy---can be leveraged for efficiency gains: output entropy for uncertainty-guided efficient training and runtime uncertainty characterization, and latent space structure for runtime generation control (with this thesis providing early exploration toward future efficient runtime interventions).

\subsection{Specific Objectives}

\subsubsection{Objective 1: Output Distribution Analysis (COMPLETED)}
\begin{itemize}[leftmargin=*]
  \item Develop automated pipeline for uncertainty quantification using entropy from output distributions
  \item Validate correlation between token-level entropy and question difficulty across domains
  \item Analyze when output entropy signals are informative vs.\ misleading
  \item \textbf{Status:} Published in arXiv:2503.01688 \cite{sychev2025uncertainty}
\end{itemize}

\subsubsection{Objective 2: Latent Space Structure Exploration (COMPLETED)}
\begin{itemize}[leftmargin=*]
  \item Investigate how high-level concepts are encoded in hidden state geometry
  \item Use language identity as a case study: identify language directions via PCA
  \item Develop inference-time steering to demonstrate practical control applications
  \item Validate across multiple language pairs (English, Spanish, Russian, Chinese, Hindi)
  \item \textbf{Status:} Published in arXiv:2510.13849 \cite{goncharov2025steering}
\end{itemize}

\subsubsection{Objective 3: Uncertainty-Guided Efficient Training (COMPLETED)}
\begin{itemize}[leftmargin=*]
  \item Use output entropy for dataset stratification by complexity (easy/medium/hard)
  \item Implement differentiated training pipelines (SFT for easy, distillation for hard)
  \item Demonstrate fine-tuning efficiency gains over baseline approaches
  \item \textbf{Status:} Published in arXiv:2506.21220 \cite{goncharov2025complexity}
\end{itemize}

\subsubsection{Objective 4: Synthesis and Thesis Completion (IN PROGRESS)}
\begin{itemize}[leftmargin=*]
  \item Articulate unified framework: output distributions for training-time and runtime efficiency, internal representations for runtime control
  \item Discuss practical implications and future directions (extending latent space exploration)
  \item Complete thesis document and defense preparation
  \item \textbf{Status:} In progress
\end{itemize}

% ============================================
% SECTION 3: LITERATURE REVIEW
% ============================================
\section{Literature Review}

This thesis draws on two complementary research traditions: (1) work analyzing output distributions for uncertainty estimation, and (2) work analyzing internal representations for interpretability and control.

\subsection{Output Distributions: Uncertainty Estimation}

Uncertainty quantification for LLMs has been approached through both black-box and white-box methods. Model-as-judge approaches \citep{zheng2023mtbench} leverage auxiliary LLMs to evaluate response quality, while token-level probability methods \citep{kadavath2022language} exploit the model's own output distributions. \citet{fadeeva2023lmpolygraph} provided comprehensive comparisons showing entropy-based methods' effectiveness for free-form responses.

However, existing work suffers from two limitations: (1) lack of domain-specific analysis connecting output entropy to question types, and (2) failure to leverage these signals for downstream applications like adaptive training. Our work addresses both gaps.

\subsection{Internal Representations: Interpretable Structure}

Work on mBERT and XLM-R revealed that high-level concepts---particularly language identity---concentrate in few principal components of hidden states, separable from semantics in parallel texts \citep{conneau2020emerging, chi2020finding}. \citet{yang2021simple} removed these components for language-agnostic embeddings. \citet{wendler2024llamas} extended this to decoder-only LLMs, revealing interpretable geometric structure in internal representations.

While prior work focused on analysis, we present early exploration of exploiting this structure for \textit{active generation control}. Language identity serves as an ideal case study: it is discrete, verifiable, and has immediate applications (code-switching mitigation). This opens the door to future efficient runtime interventions on other concepts encoded in latent space.

\subsection{Code-Switching as a Testbed}

Code-switching has been studied for mixed-language inputs \citep{aguilar2020lince, bali2014borrowing}, with recent work identifying \textit{unintended} switching in outputs \citep{ryan2024unintended, yoo2024codeswitching}. Standard mitigations require costly fine-tuning or brittle prompt engineering. We use code-switching mitigation as a practical demonstration of latent space steering, validating that manipulating internal representations can control generation behavior.

\subsection{Adaptive Training Methods}

Curriculum learning approaches \citep{kim2024strategic} order training examples from easy to hard, showing modest gains. The LIMA approach \citep{zhou2023lima} demonstrated that small, high-quality datasets suffice for alignment. SmallToLarge \citep{yang2024s2l} uses training trajectories for data selection but requires additional model training.

Knowledge distillation \citep{hsieh2023distilling} improves complex task performance but hasn't been selectively applied based on complexity. Our work bridges output distribution analysis and adaptive training, showing that distillation is beneficial specifically for high-complexity samples as identified by output entropy.

% ============================================
% SECTION 4: METHODS
% ============================================
\section{Methods}

\subsection{Study 1: Output Distribution Analysis}

\subsubsection{Experimental Design}
We developed an automated pipeline for evaluating uncertainty estimation on the MMLU-Pro benchmark \citep{wang2024mmlupro} spanning 14 topics with $\sim$12,000 questions. Four LLMs were evaluated: Phi-4, Mistral-Small-24B, Qwen-1.5B, and Qwen-72B.

\subsubsection{Signals from Output Distributions}
\paragraph{Token-wise Entropy:} For vocabulary size $k$ and output logits $\mathbf{z} = (z_1, \ldots, z_k)$, we compute:
\begin{equation}
  p_i = \frac{e^{z_i}}{\sum_{j=1}^{k} e^{z_j}}, \quad H = -\sum_{i=1}^{k} p_i \log p_i
\end{equation}

\paragraph{Model-as-Judge (MASJ):} We prompt Mistral-Large-123B to estimate (1) required education level and (2) number of reasoning steps for each question.

\subsubsection{Evaluation Protocol}
ROC-AUC scores quantify how well uncertainty predicts incorrect answers, stratified by:
\begin{itemize}[leftmargin=*]
  \item Subject domain (14 topics)
  \item Reasoning requirement (low/medium/high)
  \item Model architecture and scale
\end{itemize}

\subsection{Study 2: Latent Space Structure Exploration}

\subsubsection{Probing for Interpretable Structure}
We investigate whether high-level concepts are encoded as linear directions in hidden state space. Language identity serves as our case study due to its discrete, verifiable nature. Given parallel corpus $\mathcal{D} = \{(s, \ell)\}_{i=1}^{N}$ with semantic content $s$ in language $\ell$, we extract hidden states $\mathbf{h}_i^{(\ell)} \in \mathbb{R}^d$ from each layer. PCA identifies the first principal component as the language direction:
\begin{equation}
  \mathbf{v}^{(\ell)} = \arg\max_{\|\mathbf{v}\|=1} \sum_{i=1}^{N} \left(\mathbf{v}^\top (\mathbf{h}_i^{(\ell)} - \bar{\mathbf{h}}^{(\ell)})\right)^2
\end{equation}

\subsubsection{Steering as Validation}
To validate that the identified structure is causally meaningful, we intervene on hidden states during inference. For layers $\ell \geq \ell_{\text{crit}}$, we remove the language component:
\begin{equation}
  \tilde{\mathbf{h}}_t^{(\ell)} = \mathbf{h}_t^{(\ell)} - s \cdot (\mathbf{h}_t^{(\ell)} \cdot \mathbf{v}^{(\ell)}) \mathbf{v}^{(\ell)}
\end{equation}
where $s \in \mathbb{R}^+$ controls intervention strength.

\subsubsection{Evaluation}
\begin{itemize}[leftmargin=*]
  \item \textbf{Classification accuracy:} Logistic regression on PC1 projections
  \item \textbf{KL divergence:} Measuring distributional shift from code-switched to steered outputs
  \item \textbf{Models:} Qwen2.5-1.5B, Llama-3.2-1B
  \item \textbf{Languages:} English, Spanish, Russian, Chinese, Hindi
\end{itemize}

\subsection{Study 3: Uncertainty-Guided Efficient Training}

\subsubsection{Pipeline Overview}
\begin{enumerate}[leftmargin=*]
  \item \textbf{Complexity estimation:} Use output entropy as a signal to estimate complexity for each training sample
  \item \textbf{Data stratification:} Split dataset into easy/medium/hard terciles by entropy
  \item \textbf{Differentiated training:}
    \begin{itemize}
      \item Easy/medium: Standard SFT
      \item Hard: Chain-of-thought distillation from teacher LLM
    \end{itemize}
\end{enumerate}

\subsubsection{Baselines}
\begin{itemize}[leftmargin=*]
  \item \textbf{SFT:} Uniform supervised fine-tuning on all data
  \item \textbf{Curriculum:} Easy $\rightarrow$ medium $\rightarrow$ hard ordering
  \item \textbf{Full distillation:} CoT distillation on all data
\end{itemize}

\subsubsection{Models and Data}
Student models: Qwen2.5-3B, Phi-4-Mini. Teacher ensemble: DeepSeek-V3, Qwen-3-235B, Llama-4-Maverick. Dataset: MMLU-Pro.

% ============================================
% SECTION 5: RESULTS
% ============================================
\section{Preliminary Results}

\subsection{Study 1: Output Distribution Signals}

\subsubsection{Output Entropy Predicts Errors in Knowledge-Dependent Domains}
Token-wise entropy from output distributions achieves strong predictive performance (ROC-AUC up to 0.83 for Biology with Qwen-72B), while MASJ scores perform near-random (ROC-AUC $\approx$ 0.49).

\begin{table}[h]
  \centering
  \caption{ROC-AUC for error prediction by domain (Qwen-72B)}
  \begin{tabular}{lc}
    \toprule
    \textbf{Domain} & \textbf{ROC-AUC} \\
    \midrule
    Biology & 0.83 \\
    Economics & 0.80 \\
    Psychology & 0.77 \\
    Physics & 0.74 \\
    Mathematics & 0.73 \\
    Law & 0.69 \\
    \bottomrule
  \end{tabular}
  \label{tab:roc_auc}
\end{table}

\subsubsection{Reasoning Requirement Modulates Signal Validity}
Output entropy is a better predictor when no reasoning is required (ROC-AUC 0.79) compared to high-reasoning questions (ROC-AUC 0.73 for Qwen-72B). This suggests output distribution signals primarily capture \textit{knowledge uncertainty} rather than \textit{reasoning difficulty}.

\subsubsection{Model Scale Improves Calibration}
Larger models show clearer separation between correct (low entropy) and incorrect (high entropy) predictions. Qwen-1.5B achieves the best Expected Calibration Error (ECE = 0.242) despite smaller scale, suggesting architectural factors beyond size affect calibration.

\subsection{Study 2: Latent Space Structure}

\subsubsection{Language Identity is Linearly Encoded}
A single principal component of hidden states enables 95--99\% language classification accuracy across all tested pairs, confirming that language identity is encoded as a linear direction in latent space.

\begin{table}[h]
  \centering
  \caption{Language classification accuracy (Qwen2.5-1.5B)}
  \begin{tabular}{lc}
    \toprule
    \textbf{Language Pair} & \textbf{Accuracy} \\
    \midrule
    English - Chinese & 0.98 \\
    English - Russian & 0.99 \\
    English - Hindi & 0.98 \\
    English - Spanish & 0.95 \\
    \bottomrule
  \end{tabular}
\end{table}

\subsubsection{Steering Validates Causal Role of Structure}
Intervening on the identified language direction causally affects generation. KL divergence from original (English) distribution decreases by up to 42\% after steering, demonstrating that latent space structure can be exploited for control:

\begin{table}[h]
  \centering
  \caption{KL divergence reduction via steering}
  \begin{tabular}{lcc}
    \toprule
    \textbf{Language Pair} & \textbf{Before} & \textbf{After} \\
    \midrule
    English - Chinese & 8.94 & 5.19 \\
    English - Russian & 7.78 & 5.43 \\
    English - Spanish & 6.37 & 5.86 \\
    \bottomrule
  \end{tabular}
\end{table}

\subsubsection{Structure Emerges Progressively Through Layers}
Explained variance for PC1 peaks in final layers ($\sim$10\% at layer 16 for Llama-3.2), with clusters emerging loosely in early layers and sharpening dramatically toward the output. This reveals how the model progressively refines high-level concepts, and identifies where latent space structure becomes most amenable to intervention. The concentration in later layers also connects internal representations to output distributions, as these layers most directly influence the final logits.

\subsection{Study 3: Uncertainty-Guided Efficient Training}

\subsubsection{Significant Accuracy Improvements}
Our pipeline, using output entropy to guide data stratification, achieves substantial gains over baselines:

\begin{table}[h]
  \centering
  \caption{Accuracy after 20 epochs}
  \begin{tabular}{lcc}
    \toprule
    \textbf{Method} & \textbf{Qwen 3B} & \textbf{Phi4-mini} \\
    \midrule
    SFT (baseline) & 0.39 & 0.51 \\
    Curriculum & 0.45 & 0.54 \\
    Distillation (all data) & 0.50 & 0.63 \\
    \textbf{Pipeline (ours)} & \textbf{0.52} & \textbf{0.64} \\
    \bottomrule
  \end{tabular}
\end{table}

\subsubsection{81\% Data Efficiency Improvement}
Our pipeline matches or exceeds full distillation while using only 19\% of the tokens:
\begin{itemize}[leftmargin=*]
  \item Qwen 3B: 7.98k tokens (ours) vs.\ 39.45k (full distillation)
  \item Phi4-mini: 5.35k tokens (ours) vs.\ 30.30k (full distillation)
\end{itemize}

\subsubsection{Output Entropy Outperforms MASJ for Complexity}
Single-token output entropy achieves ROC-AUC 0.72--0.74 for complexity estimation, while MASJ reasoning scores achieve only 0.54--0.57. This validates output distributions as a reliable signal source for guiding training strategies.

% ============================================
% REFERENCES
% ============================================
\section{List of References}

\begin{thebibliography}{99}

  \bibitem[Sychev et al.(2025)]{sychev2025uncertainty}
  Sychev, P., Goncharov, A., Vyazhev, D., Khalafyan, E., \& Zaytsev, A. (2025).
  When an LLM is Apprehensive About Its Answers -- And When Its Uncertainty Is Justified.
  \textit{arXiv preprint arXiv:2503.01688}.

  \bibitem[Goncharov et al.(2025a)]{goncharov2025complexity}
  Goncharov, A., Vyazhev, D., Sychev, P., Khalafyan, E., \& Zaytsev, A. (2025).
  Complexity-aware fine-tuning.
  \textit{arXiv preprint arXiv:2506.21220}.

  \bibitem[Goncharov et al.(2025b)]{goncharov2025steering}
  Goncharov, A., Kondusov, N., \& Zaytsev, A. (2025).
  Language steering in latent space to mitigate unintended code-switching.
  \textit{arXiv preprint arXiv:2510.13849}.

  \bibitem[Zheng et al.(2023)]{zheng2023mtbench}
  Zheng, L., et al. (2023).
  Judging LLM-as-a-judge with MT-bench and Chatbot Arena.
  \textit{NeurIPS}.

  \bibitem[Kadavath et al.(2022)]{kadavath2022language}
  Kadavath, S., et al. (2022).
  Language models (mostly) know what they know.
  \textit{arXiv preprint arXiv:2207.05221}.

  \bibitem[Fadeeva et al.(2023)]{fadeeva2023lmpolygraph}
  Fadeeva, E., et al. (2023).
  LM-polygraph: Uncertainty estimation for language models.
  \textit{EMNLP System Demonstrations}.

  \bibitem[Conneau et al.(2020)]{conneau2020emerging}
  Conneau, A., et al. (2020).
  Emerging cross-lingual structure in pretrained language models.
  \textit{ACL}.

  \bibitem[Chi et al.(2020)]{chi2020finding}
  Chi, E.A., Hewitt, J., \& Manning, C.D. (2020).
  Finding universal grammatical relations in multilingual BERT.
  \textit{ACL}.

  \bibitem[Wendler et al.(2024)]{wendler2024llamas}
  Wendler, C., et al. (2024).
  Do LLamas work in English? On the latent language of multilingual transformers.
  \textit{ACL}.

  \bibitem[Aguilar et al.(2020)]{aguilar2020lince}
  Aguilar, G., Kar, S., \& Solorio, T. (2020).
  LinCE: A centralized benchmark for linguistic code-switching evaluation.
  \textit{LREC}.

  \bibitem[Bali et al.(2014)]{bali2014borrowing}
  Bali, K., et al. (2014).
  ``I am borrowing ya mixing?'' An analysis of English-Hindi code mixing in Facebook.
  \textit{First Workshop on Computational Approaches to Code Switching}.

  \bibitem[Ryan et al.(2024)]{ryan2024unintended}
  Ryan, M.J., Held, W., \& Yang, D. (2024).
  Unintended impacts of LLM alignment on global representation.
  \textit{ACL}.

  \bibitem[Yoo et al.(2024)]{yoo2024codeswitching}
  Yoo, H., Yang, Y., \& Lee, H. (2024).
  Code-switching red-teaming: LLM evaluation for safety and multilingual understanding.
  \textit{arXiv preprint arXiv:2406.15481}.

  \bibitem[Yang(2021)]{yang2021simple}
  Yang, Z., et al. (2021).
  A simple and effective method to eliminate the self language bias in multilingual representations.
  \textit{EMNLP}.

  \bibitem[Kim \& Lee(2024)]{kim2024strategic}
  Kim, J., \& Lee, J. (2024).
  Strategic data ordering: Enhancing large language model performance through curriculum learning.
  \textit{arXiv preprint}.

  \bibitem[Zhou et al.(2023)]{zhou2023lima}
  Zhou, C., et al. (2023).
  LIMA: Less is more for alignment.
  \textit{arXiv preprint arXiv:2305.11206}.

  \bibitem[Yang et al.(2024)]{yang2024s2l}
  Yang, Y., et al. (2024).
  SmallToLarge (S2L): Scalable data selection for fine-tuning large language models.
  \textit{arXiv preprint arXiv:2403.07384}.

  \bibitem[Hsieh et al.(2023)]{hsieh2023distilling}
  Hsieh, C.-Y., et al. (2023).
  Distilling step-by-step! Outperforming larger language models with less training data and smaller model sizes.
  \textit{ACL}.

  \bibitem[Wang et al.(2024)]{wang2024mmlupro}
  Wang, Y., et al. (2024).
  MMLU-Pro: A more robust and challenging multi-task language understanding benchmark.
  \textit{NeurIPS}.

\end{thebibliography}

% ============================================
% APPENDIX
% ============================================
\newpage
\section*{Appendix: Publications and Resources}

\subsection*{A. Published Papers}

\begin{enumerate}[leftmargin=*]
  \item \textbf{Sychev, P., Goncharov, A., Vyazhev, D., Khalafyan, E., \& Zaytsev, A.} (2025). ``When an LLM is Apprehensive About Its Answers -- And When Its Uncertainty Is Justified.'' \textit{arXiv:2503.01688}.
    \begin{itemize}
      \item GitHub: \url{https://github.com/LabARSS/question-complexity-estimation}
    \end{itemize}

  \item \textbf{Goncharov, A., Vyazhev, D., Sychev, P., Khalafyan, E., \& Zaytsev, A.} (2025). ``Complexity-aware fine-tuning.'' \textit{arXiv:2506.21220}.
    \begin{itemize}
      \item GitHub: \url{https://github.com/LabARSS/complexity-aware-fine-tuning}
    \end{itemize}

  \item \textbf{Goncharov, A., Kondusov, N., \& Zaytsev, A.} (2025). ``Language steering in latent space to mitigate unintended code-switching.'' \textit{arXiv:2510.13849}.
    \begin{itemize}
      \item GitHub: \url{https://github.com/fxlrnrpt/language-steering-in-latent-space}
    \end{itemize}
\end{enumerate}

\subsection*{B. Key Findings Summary}

\begin{table}[h]
  \centering
  \caption{Summary of thesis contributions}
  \begin{tabular}{p{3cm}p{2.5cm}p{3.5cm}p{4cm}p{2cm}}
    \toprule
    \textbf{Study} & \textbf{Stage} & \textbf{Signal Source} & \textbf{Main Finding} & \textbf{Metric} \\
    \midrule
    Output Distributions & Runtime & Token entropy & Predicts errors in knowledge domains & ROC-AUC 0.83 \\
    Latent Space Structure & Runtime & Hidden states & Language encoded linearly; steering controls generation & 42\% KL red. \\
    Uncertainty-Guided Training & Training & Token entropy & Matches distillation with 19\% data & 0.52/0.64 acc. \\
    \bottomrule
  \end{tabular}
\end{table}

\subsection*{C. Datasets Released}

\begin{itemize}[leftmargin=*]
  \item MMLU-Pro with token probability distributions
  \item Chain-of-thought responses with entropy annotations
  \item Parallel translation embeddings for language steering
\end{itemize}

\end{document}
